<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" style="height:64px;margin-right:32px"/>

# 1. Product name - VibeSec - Test your vibe coded apps before launch

2. Backend Framework - FastAPI
3. Deployment platform - Vercel
4.Database - PostgresSQL
Authentication - We can use Firebase Auth
4. Default LLM Provider - Gemini, but give option for OpenAI key as well.
5. Ollama Integration - no
6. Fix Application Strategy: Should AI-generated fixes be:- Display the user the fixes and give the option of creating a PR or copy the code snippets directly.
7. Business Model: can be decided later, create this in the PRD but for now place a placeholder.
8. LLM Cost Handling: we do not offer that, just ask the user to put their API key for the llm integration.
9. MVP vs Post-MVP - whatever we discussed is MVP, rest of the features we add later.
10. Language/Framework Support: Which languages/frameworks should we support in MVP?JavaScript/TypeScript (Next.js, Express, Node), Python (Django, FastAPI)
11. DAST in MVP: Post-MVP (start with SAST + SCA only)
12. CI/CD Integration - GitHub Actions
13. User Experience
Onboarding Flow: Should new users: Start with a demo project to explore features > Required to connect GitHub immediately > yest they also have an option for manual code upload (zip file)
14. focus on only single app repos

continue to make a detailed PRD with all our discussions

```markdown
# VibeSec — Product Requirements Document (PRD)
**Tagline:** Test your vibe-coded apps before launch

## 1. Product Overview

### 1.1 Vision & Problem Statement
VibeSec is a testing and security platform focused on **AI-generated / vibe-coded web applications**. Many developers now rely heavily on AI coding assistants or IDE copilots to scaffold applications quickly, but:

- They ship **with minimal tests** (if any) and fragile happy-path coverage.
- They include **security vulnerabilities** typical of LLM-generated code (hardcoded secrets, unsafe string interpolation, missing validation).
- They lack **production readiness** in areas like observability, resilience, and CI/CD.

VibeSec helps developers move from “this kinda works on localhost” to “this is safe and production-ready” by providing:

- Automated static analysis (SAST) and dependency scanning (SCA) tuned for vibe-coded apps.
- A production readiness score and checklist.
- LLM-assisted remediation: code fixes and test generation, using the user’s own LLM API keys (Gemini or OpenAI).
- A premium SaaS dashboard with clear, visual insights.

### 1.2 Target Users

**Primary:**
- Indie hackers, solo devs, and small teams (2–10 developers) who:
  - Use AI tools (e.g., Cursor, Copilot, ChatGPT) to generate most of their app code.
  - Deploy web apps on services like Vercel, Railway, Render, Fly.io.
  - Want a “safety check” before launch or client handoff.

**Secondary:**
- Agencies/freelance devs delivering apps to clients and needing a structured readiness report.
- Small product teams in startups using AI codegen heavily.

### 1.3 Goals & Non-Goals

**Goals (MVP):**
- Provide an automated **readiness score** for a repo (single app) across security, testing, reliability, observability, performance, and infrastructure.
- Run **SAST + SCA** for supported stacks (Next.js, Express/Node, Django, FastAPI).
- Provide **LLM-generated fixes and test suggestions** and allow users to create PRs or copy code snippets.
- Offer a **premium SaaS dashboard** with rich visualizations and organized insights.
- Allow users to configure and securely store their **own LLM API keys** for Gemini or OpenAI.
- Integrate with **GitHub** (repos + Actions) and allow **manual ZIP upload**.
- Support **single-app repos** (no monorepo support in MVP).

**Non-Goals (for Post-MVP):**
- DAST (runtime / black-box testing).
- Multi-repo/monorepo and multi-service dependency graphs.
- Full compliance frameworks (SOC2/HIPAA/PCI checklists).
- Team collaboration features and RBAC.
- Extensive CI/CD ecosystem (beyond GitHub Actions).

---

## 2. Scope & Feature Breakdown (MVP)

### 2.1 Functional Scope

**Included in MVP:**
1. Project onboarding:
   - Demo project to explore VibeSec.
   - Connect GitHub repo (single app).
   - Manual code upload (ZIP).
2. Automated analysis:
   - SAST (Semgrep/CodeQL-like rules tuned for AI-generated code).
   - SCA (dependency scanning).
3. Production readiness evaluation:
   - Readiness score and domain sub-scores.
   - Checklist of key items.
4. LLM-assisted remediation:
   - Fix suggestions (code diffs).
   - Test case generation.
   - User can:
     - Create GitHub PR from fixes.
     - Copy code snippets directly.
5. Dashboards & reporting:
   - Project dashboard.
   - Detailed domain views (Security, Testing, Reliability, Observability, Performance, Infrastructure).
6. CI/CD integration:
   - GitHub Actions workflow template.
   - PR checks (readiness status).
7. LLM configuration & secure API key storage:
   - Default provider: **Gemini** (user-provided key).
   - Optional: OpenAI key (user-provided).
   - No Ollama; no platform-managed LLM billing.

**Explicitly excluded from MVP (Post-MVP candidates):**
- DAST integration (ZAP/Burp).
- Team workspaces & collaboration.
- Slack/webhook notifications.
- Advanced policy management and custom rule builder.
- Benchmarking against similar apps.

---

## 3. Use Cases & User Journeys

### 3.1 Primary Use Cases

1. **“I shipped a Next.js app via AI, is it safe?”**
   - User connects GitHub repo.
   - Runs scan.
   - Reviews readiness score and vulnerabilities.
   - Applies LLM-generated fixes and test additions via PR.

2. **“I’m delivering a Django app to a client and need a report.”**
   - User uploads project ZIP.
   - Runs scan and gets structured report.
   - Exports findings and uses AI fixes/tests where appropriate.

3. **“I want to keep my app safe as it evolves.”**
   - Sets up GitHub Actions workflow.
   - VibeSec scan runs on PRs.
   - Readiness check must pass before merge.

### 3.2 High-Level User Journey

1. **Sign-up & Auth**
   - User visits VibeSec, signs up via Firebase Auth (Google/email+password).
   - On first login, user sees an onboarding wizard and a demo project.

2. **Demo Project Exploration**
   - Demo project already scanned.
   - User explores dashboard: readiness score, security issues, coverage gaps, and fix suggestions.

3. **Connect GitHub Repository**
   - User is prompted to:
     - Connect GitHub (OAuth).
     - Grant repo access (scoped).
   - User selects a single repo to onboard as a project.

4. **Initial Scan**
   - Repo is cloned into a secure environment.
   - Stack detection runs (Next.js/Express/Django/FastAPI).
   - SAST and SCA scans run in parallel.
   - Progress displayed in real time.
   - User sees readiness score and breakdown upon completion.

5. **Review Results & Apply Fixes**
   - User views findings in the premium dashboard.
   - For each critical/high issue:
     - VibeSec shows LLM-generated code fixes & tests.
     - User can:
       - Create GitHub PR (one per finding or batched).
       - Copy patch/test code to paste manually.

6. **Configure LLM Provider (Gemini/OpenAI)**
   - User goes to Settings → AI & LLM.
   - Chooses provider (Gemini or OpenAI).
   - Enters API key and endpoint where applicable.
   - VibeSec validates key and stores it encrypted.
   - All future remediation uses user’s LLM credentials.

7. **CI Integration**
   - User installs provided GitHub Action workflow file.
   - Future PRs trigger VibeSec scan and annotate PR with status and summary comment.

8. **Ongoing Use**
   - User periodically re-scans after major changes.
   - Uses readiness score trends to track improvements.

---

## 4. Functional Requirements

### 4.1 Project Management

**FR-1: Create Project**
- Inputs:
  - Project name (auto-filled from repo).
  - Source:
    - GitHub repository (required for primary flow).
    - ZIP upload (optional alt flow).
- System:
  - Detects language/framework (Next.js, Express, Django, FastAPI).
  - Stores project metadata in Postgres.
- Constraints:
  - Single app repos only (no monorepo detection or configuration in MVP).

**FR-2: Project List & Status**
- Display all projects with:
  - Name.
  - Latest readiness score.
  - Last scan timestamp.
  - Latest scan status (Success/Failed/In Progress).
- Actions:
  - View details.
  - Trigger new scan.

### 4.2 Scanning & Analysis

**FR-3: Stack Detection**
- Inspects repository to determine framework:
  - Next.js: `next.config.*`, `app/` or `pages/`, `package.json` deps.
  - Express/Node: `express` in `package.json`, index/server files.
  - Django: `manage.py`, `settings.py`, `django` in `requirements.txt`.
  - FastAPI: `fastapi` in `requirements.txt`, `uvicorn` etc.

**FR-4: SAST (Static Analysis)**
- For supported languages/frameworks, run:
  - JavaScript/TypeScript: Semgrep-like rulesets focused on:
    - SQL injection.
    - XSS.
    - Insecure deserialization.
    - Insecure cookie/session handling.
    - Hardcoded secrets and credentials.
  - Python: Similar patterns for Django/FastAPI.
- Output:
  - Finding ID.
  - Severity (Critical/High/Medium/Low).
  - Location (file, line).
  - CWE/OWASP tag.
  - Description and recommended fix pattern.

**FR-5: SCA (Dependency Scanning)**
- Parse dependency files:
  - JS/TS: `package.json` + `package-lock.json` / `yarn.lock`.
  - Python: `requirements.txt` / `poetry.lock`.
- Query CVE databases (via local DB or external service).
- Output:
  - Package name.
  - Current version.
  - Vulnerabilities and severity.
  - Recommended minimal safe version.

**FR-6: Production Readiness Scoring**
- Compute a **Readiness Score** (0–100) and domain sub-scores:
  - Security (25%)
  - Testing (20%)
  - Reliability (20%)
  - Observability (15%)
  - Performance (10%)
  - Infrastructure (10%)
- Domain-specific inputs:
  - Security:
    - Number and severity of SAST/SCA findings.
    - Presence of typical anti-patterns (e.g., string interpolation in queries).
  - Testing:
    - Code coverage % (from coverage reports if present).
    - Presence of test frameworks (Jest, Pytest, etc.).
    - Detection of tests for critical modules.
  - Reliability:
    - Presence of retry logic, error handling.
    - Usage of environment-based configuration.
  - Observability:
    - Presence of structured logging, health endpoints (`/health`, `/ready`).
  - Performance:
    - Basic heuristics (e.g., presence of caching, N+1 patterns detection).
  - Infrastructure:
    - CI config presence.
    - Environment-based secrets usage (no hardcoded keys).

- Output:
  - Overall score with color-coded interpretation:
    - 0–59: Red (Not ready).
    - 60–84: Yellow (Needs work).
    - 85–100: Green (Ready).
  - Domain scorecards.

**FR-7: Scan Orchestration**
- Orchestrator service schedules:
  - Code clone/pull.
  - SAST job.
  - SCA job.
- Progress updates sent via WebSockets:
  - States: Pending, Running, Completed, Failed.
  - Per-job progress (%).

### 4.3 LLM-Assisted Remediation

**FR-8: LLM Configuration (Settings UI)**
- User can configure:
  - Provider: Gemini (default) or OpenAI.
  - API key (required).
  - Optional endpoint (for custom proxies, if user wants).
- Backend:
  - Validates credentials by calling provider (e.g., list models).
  - Encrypts API key with AES-256-GCM before storing in Postgres.
  - Uses a key stored in a secure KMS/secret manager.
- No VibeSec-managed LLM billing: user bears their LLM costs via their keys.

**FR-9: Fix Generation**
- For each SAST/SCA finding:
  - Build a structured prompt with:
    - Vulnerability details.
    - Code snippet (±10 lines context).
    - Language and framework.
    - Security best practices reference.
  - Call chosen LLM (Gemini or OpenAI) with user’s API key.
  - Receive:
    - Fixed code snippet (or diff).
    - Explanation of fix.
    - Optional test case to cover vulnerability.

- UI:
  - Show original and fixed code side-by-side or in diff view.
  - Display explanation and test case below.

**FR-10: Apply Fix (PR / Copy)**
- User actions for each fix:
  - **Create PR**:
    - Backend:
      - Generate patch file.
      - Create a new branch.
      - Commit changes.
      - Open PR via GitHub API with:
        - Title: `[VibeSec] Fix SQL Injection in auth/login`.
        - Description including explanation, tests added, and references.
  - **Copy Snippet**:
    - UI copy button for fixed code and tests to paste manually.

### 4.4 CI/CD Integration

**FR-11: GitHub Actions Template**
- Provide pre-built workflow YAML:
  - Triggers:
    - On `pull_request`.
    - On `push` to `main` if desired.
  - Steps:
    - Checkout code.
    - Call VibeSec API to trigger scan.
    - Wait for scan completion.
    - Parse results and:
      - Fail workflow if readiness score < threshold or new Critical/High findings appear.
      - Post summary comment on PR (via GitHub API).

**FR-12: PR Status Reporting**
- For each PR scanned:
  - Show GitHub check status:
    - ✅ Ready (score ≥ threshold).
    - ⚠️ Warnings.
    - ❌ Not ready (critical issues).
  - Provide a summary comment:
    - Current readiness score & previous score.
    - Count of new critical/high issues.
    - Link to VibeSec scan details.

### 4.5 Onboarding & Experience

**FR-13: Demo Project**
- Demo project pre-loaded and scanned with realistic issues.
- User can explore:
  - Readiness score.
  - Dashboard and detailed views.
  - Example LLM-generated fixes (mock or precomputed).

**FR-14: GitHub Onboarding**
- Step 1: Connect GitHub via OAuth.
- Step 2: Select repository (single app).
- Step 3: Trigger first scan.

**FR-15: Manual ZIP Upload**
- User uploads source code ZIP.
- Backend:
  - Unzips into temporary directory.
  - Runs same stack detection and scanning.
- Note: PR creation is only available for GitHub-connected projects; for ZIP-based projects, only code snippets can be copied.

---

## 5. Non-Functional Requirements

### 5.1 Performance
- Initial full scan for typical-sized project (<100k LOC) finishes within **5–10 minutes**.
- Dashboard loads within **<1.5 seconds** on 4G connections.
- WebSocket updates at least every **3 seconds** during scan execution.

### 5.2 Security
- All communication via HTTPS.
- API keys and any secrets:
  - Encrypted at rest (AES-256-GCM).
  - Not exposed to frontend after initial submit.
- Auth:
  - Firebase Auth for user accounts.
- Least privilege:
  - GitHub scopes limited to repo access required for scans and PR creation.
- Logging:
  - Avoid logging code contents and API keys.
  - Only log metadata and anonymized metrics.

### 5.3 Reliability
- Scan jobs are retried up to 3 times on transient failures.
- Queue-backed job processing to avoid timeouts.
- At-least-once scan processing; idempotent result recording.

### 5.4 Privacy & Compliance
- Allow users to delete projects and associated data.
- Allow users to delete stored LLM API keys at any time.
- Document how code is stored and for how long (configurable retention).

---

## 6. Architecture & Tech Stack

### 6.1 Frontend

- **Framework:** Next.js 14 (App Router) with TypeScript.
- **Styling:** Tailwind CSS, shadcn/ui, custom theme.
- **State/Data:** React Query (TanStack Query) for API calls and caching.
- **Charting:** Recharts/Tremor for charts and analytics.
- **Auth:** Integrate Firebase Auth SDK (using tokens for backend auth).

**Key Pages:**
- `/` — Marketing + CTA.
- `/dashboard` — Project list + global summary.
- `/projects/[id]` — Project overview, readiness scores, and tabbed detail views.
- `/projects/[id]/scan/[scanId]` — Detailed scan results.
- `/settings` — LLM configuration, account settings.

### 6.2 Backend

- **Framework:** FastAPI.
- **DB:** PostgreSQL.
- **Cache/Queue:** Redis (job queue for scans).
- **Storage:** Object storage (e.g., S3-compatible) for:
  - Uploaded ZIPs.
  - Optional artifacts (scan reports).

**Key Services/Modules:**
- **API Gateway** (FastAPI app):
  - Auth verification (Firebase token verification).
  - REST endpoints for projects, scans, settings.
- **Scan Orchestrator:**
  - Accepts scan requests, schedules jobs in Redis-backed queue.
  - Triggers SAST and SCA jobs.
- **Analysis Services:**
  - SAST Runner (per language stack).
  - SCA Runner (dependency scanner).
- **Scoring Engine:**
  - Aggregates findings and generates readiness score.
- **LLM Service:**
  - Provider abstraction (Gemini/OpenAI).
  - Handles prompt building, API calls, and response parsing.
- **GitHub Integration Service:**
  - Repo linking and repo metadata.
  - PR creation and PR status updates.
  - Webhook receiver for events.

### 6.3 Firebase Auth Integration

- Frontend:
  - Uses Firebase Auth to obtain ID tokens.
- Backend:
  - Validates tokens using Firebase Admin SDK or public keys.
  - Maps Firebase UID to internal user record in Postgres.

---

## 7. UX & UI Details (Premium SaaS Experience)

### 7.1 Main Dashboard

**Components:**
- Global header with:
  - Logo (VibeSec).
  - Navigation: Projects, Scans, Settings.
  - User avatar/menu.
- Primary panel:
  - Readiness score summary over all projects.
  - Trend chart for average readiness over time.
  - Table of projects with statuses.

### 7.2 Project Overview

**Top Section:**
- Project name, repo link.
- Big circular readiness score (with animation).
- Status pill (Ready / Needs work / Not ready).
- Last scan timestamp and trend (e.g., +10 vs last week).

**Score Breakdown Cards:**
- Six small cards: Security, Testing, Reliability, Observability, Performance, Infrastructure.
- Each with:
  - Score (0–100).
  - Color-coded bar.
  - Quick status indicator (Good/Fair/Poor).

### 7.3 Detailed Views

**Security Tab:**
- Donut chart of severity distribution.
- Line chart of vulnerability counts over time.
- Table of SAST and SCA findings with filters:
  - Severity.
  - Category (Auth, Input Validation, Secrets, etc.).
- Click a finding → opens drawer/modal with:
  - Code snippet.
  - LLM-generated fix & explanation.
  - Buttons: “Create PR” / “Copy Fix” / “Copy Test”.

**Testing Tab:**
- Coverage summary (if coverage reports detected).
- Coverage by module heatmap.
- List of files with low coverage.
- Button: “Generate Tests for These Areas.”

**Reliability & Observability Tabs:**
- Presence of health endpoints, retry logic, structured logging.
- Checklists with checkmarks and suggestions.

**Performance Tab:**
- Simple heuristics and code smell detection (e.g., N+1 queries).
- Recommended optimizations.

**Infrastructure Tab:**
- CI presence, environment variable usage, hardcoded secrets.

### 7.4 Settings → LLM Configuration

- Provider selection (Gemini/OpenAI).
- API key fields (with masked values).
- “Test Connection” button.
- Status indicators (Connected/Failed).
- Advanced options (temperature, max tokens) kept minimal in MVP; can be expanded later.

---

## 8. Business Model (Placeholder)

> **Note:** Detailed pricing and packaging to be defined later.

### 8.1 Initial Thoughts (Non-binding)

- **Free Tier:**
  - 1 project.
  - Limited scans/month.
  - Limited use of LLM fixes/tests.

- **Pro Tier:**
  - Multiple projects.
  - Higher scan limits.
  - Full LLM integration (user-managed keys).
  - GitHub Actions integration.

- **Team Tier (Post-MVP):**
  - Multiple seats.
  - Collaboration features.
  - Extended analytics and compliance reports.

---

## 9. Release Plan (MVP)

### 9.1 Milestones

1. **M1 — Foundations (Infra & Auth)**
   - FastAPI backend skeleton.
   - PostgreSQL schema.
   - Next.js frontend skeleton.
   - Firebase Auth integration end-to-end.
   - Basic project creation (no scans yet).

2. **M2 — Scanning Core (SAST + SCA)**
   - Repo cloning & ZIP handling.
   - Stack detection and SAST runners.
   - SCA integration.
   - Store findings in DB.
   - Simple dashboard for listing findings.

3. **M3 — Readiness Score & Dashboard UX**
   - Scoring engine.
   - Visual scorecards and charts.
   - Project overview UI (premium look & feel).
   - Demo project fully wired.

4. **M4 — LLM Remediation (Gemini/OpenAI)**
   - LLM configuration in settings.
   - Secure key storage and validation.
   - Fix generation pipelines.
   - UI for viewing fixes and tests.

5. **M5 — GitHub Actions Integration**
   - Workflow template.
   - Scan trigger endpoints.
   - PR status checks and comments.

6. **M6 — Polish & Beta**
   - Error handling and edge cases.
   - Performance tuning.
   - Basic analytics (usage metrics).
   - Documentation & onboarding content.

---

## 10. Success Metrics

- **Adoption:**
  - # of projects onboarded in first 3 months.
- **Engagement:**
  - Average scans/project per month.
  - % of scans where at least one LLM fix is viewed.
- **Impact:**
  - Average decrease in critical vulnerabilities between first and third scan of a project.
  - Average readiness score improvement over time.
- **Conversion (post-pricing):**
  - Free → Paid conversion rate.

---

## 11. Open Questions / Future Extensions (Post-MVP)

- Add DAST and runtime testing.
- Support for more languages/frameworks (Go, Rust, Java, PHP).
- Team collaboration (commenting, approvals, RBAC).
- Notifications (Slack, webhooks, email digests).
- Monorepo and multi-service dependency views.
- Compliance-specific views (PCI, SOC2, HIPAA).
- Self-hosted/on-prem version.

---

**This PRD is intended as the single source of truth (“bible”) for implementing VibeSec in an IDE like Antigravity: covering frontend, backend, integrations, flows, and constraints for the MVP.**
```

